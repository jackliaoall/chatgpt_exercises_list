{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNYP/ruBVXal5kMyJA82YPw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"lFUdI7Ae4AAt"},"outputs":[],"source":["import requests\n","\n","res = requests.get('https://cdn.openai.com/papers/gpt-4.pdf')\n","with open('gpt-4.pdf', 'wb') as f:\n","  f.write(res.content)"]},{"cell_type":"code","source":["!pip install pypdf"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b7h6urpa4eRc","executionInfo":{"status":"ok","timestamp":1679835540682,"user_tz":-480,"elapsed":7867,"user":{"displayName":"Liao Jack","userId":"16157886839679822522"}},"outputId":"5e86056b-09ad-4fa8-c84e-1053acd6161c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pypdf\n","  Downloading pypdf-3.6.0-py3-none-any.whl (245 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.7/245.7 KB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing_extensions>=3.10.0.0 in /usr/local/lib/python3.9/dist-packages (from pypdf) (4.5.0)\n","Installing collected packages: pypdf\n","Successfully installed pypdf-3.6.0\n"]}]},{"cell_type":"code","source":["from pypdf import PdfReader\n","\n","reader = PdfReader(\"gpt-4.pdf\")\n","number_of_pages = len(reader.pages)\n","page = reader.pages[0]\n","text = page.extract_text()"],"metadata":{"id":"JzoH2oAT4iMm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":140},"id":"TnRUymia4tL4","executionInfo":{"status":"ok","timestamp":1679835540683,"user_tz":-480,"elapsed":7,"user":{"displayName":"Liao Jack","userId":"16157886839679822522"}},"outputId":"66ae95e9-d0f7-45d1-e244-75bc2d5689d4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'GPT-4 Technical Report\\nOpenAI\\x03\\nAbstract\\nWe report the development of GPT-4, a large-scale, multimodal model which can\\naccept image and text inputs and produce text outputs. While less capable than\\nhumans in many real-world scenarios, GPT-4 exhibits human-level performance\\non various professional and academic benchmarks, including passing a simulated\\nbar exam with a score around the top 10% of test takers. GPT-4 is a Transformer-\\nbased model pre-trained to predict the next token in a document. The post-training\\nalignment process results in improved performance on measures of factuality and\\nadherence to desired behavior. A core component of this project was developing\\ninfrastructure and optimization methods that behave predictably across a wide\\nrange of scales. This allowed us to accurately predict some aspects of GPT-4’s\\nperformance based on models trained with no more than 1/1,000th the compute of\\nGPT-4.\\n1 Introduction\\nThis technical report presents GPT-4, a large multimodal model capable of processing image and\\ntext inputs and producing text outputs. Such models are an important area of study as they have the\\npotential to be used in a wide range of applications, such as dialogue systems, text summarization,\\nand machine translation. As such, they have been the subject of substantial interest and progress in\\nrecent years [1–34].\\nOne of the main goals of developing such models is to improve their ability to understand and generate\\nnatural language text, particularly in more complex and nuanced scenarios. To test its capabilities\\nin such scenarios, GPT-4 was evaluated on a variety of exams originally designed for humans. In\\nthese evaluations it performs quite well and often outscores the vast majority of human test takers.\\nFor example, on a simulated bar exam, GPT-4 achieves a score that falls in the top 10% of test takers.\\nThis contrasts with GPT-3.5, which scores in the bottom 10%.\\nOn a suite of traditional NLP benchmarks, GPT-4 outperforms both previous large language models\\nand most state-of-the-art systems (which often have benchmark-speciﬁc training or hand-engineering).\\nOn the MMLU benchmark [ 35,36], an English-language suite of multiple-choice questions covering\\n57 subjects, GPT-4 not only outperforms existing models by a considerable margin in English, but\\nalso demonstrates strong performance in other languages. On translated variants of MMLU, GPT-4\\nsurpasses the English-language state-of-the-art in 24 of 26 languages considered. We discuss these\\nmodel capability results, as well as model safety improvements and results, in more detail in later\\nsections.\\nThis report also discusses a key challenge of the project, developing deep learning infrastructure and\\noptimization methods that behave predictably across a wide range of scales. This allowed us to make\\npredictions about the expected performance of GPT-4 (based on small runs trained in similar ways)\\nthat were tested against the ﬁnal run to increase conﬁdence in our training.\\nDespite its capabilities, GPT-4 has similar limitations to earlier GPT models [ 1,37,38]: it is not fully\\nreliable (e.g. can suffer from “hallucinations”), has a limited context window, and does not learn\\n\\x03Please cite this work as “OpenAI (2023)\". Full authorship contribution statements appear at the end of the\\ndocument.arXiv:2303.08774v2  [cs.CL]  16 Mar 2023'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["!pip install nltk"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8pd2LVDA4xhp","executionInfo":{"status":"ok","timestamp":1679835547202,"user_tz":-480,"elapsed":6525,"user":{"displayName":"Liao Jack","userId":"16157886839679822522"}},"outputId":"922a9ce2-e3be-4537-dc00-1c31385983f0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (3.8.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk) (8.1.3)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk) (2022.10.31)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk) (4.65.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk) (1.1.1)\n"]}]},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6w3MC7KP5FX1","executionInfo":{"status":"ok","timestamp":1679835549614,"user_tz":-480,"elapsed":2415,"user":{"displayName":"Liao Jack","userId":"16157886839679822522"}},"outputId":"491efc05-0cb7-4531-e6e5-af31fd40e660"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["from nltk.tokenize import sent_tokenize\n","sentences = sent_tokenize(text)"],"metadata":{"id":"cPToNwu94z73"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for sentence in sentences:\n","    print(sentence)\n","    print('=' * 20)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9oWAMm6E5I_2","executionInfo":{"status":"ok","timestamp":1679835549615,"user_tz":-480,"elapsed":8,"user":{"displayName":"Liao Jack","userId":"16157886839679822522"}},"outputId":"6c4ac60e-6ce8-425b-a1bf-5e0636021a50"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["GPT-4 Technical Report\n","OpenAI\u0003\n","Abstract\n","We report the development of GPT-4, a large-scale, multimodal model which can\n","accept image and text inputs and produce text outputs.\n","====================\n","While less capable than\n","humans in many real-world scenarios, GPT-4 exhibits human-level performance\n","on various professional and academic benchmarks, including passing a simulated\n","bar exam with a score around the top 10% of test takers.\n","====================\n","GPT-4 is a Transformer-\n","based model pre-trained to predict the next token in a document.\n","====================\n","The post-training\n","alignment process results in improved performance on measures of factuality and\n","adherence to desired behavior.\n","====================\n","A core component of this project was developing\n","infrastructure and optimization methods that behave predictably across a wide\n","range of scales.\n","====================\n","This allowed us to accurately predict some aspects of GPT-4’s\n","performance based on models trained with no more than 1/1,000th the compute of\n","GPT-4.\n","====================\n","1 Introduction\n","This technical report presents GPT-4, a large multimodal model capable of processing image and\n","text inputs and producing text outputs.\n","====================\n","Such models are an important area of study as they have the\n","potential to be used in a wide range of applications, such as dialogue systems, text summarization,\n","and machine translation.\n","====================\n","As such, they have been the subject of substantial interest and progress in\n","recent years [1–34].\n","====================\n","One of the main goals of developing such models is to improve their ability to understand and generate\n","natural language text, particularly in more complex and nuanced scenarios.\n","====================\n","To test its capabilities\n","in such scenarios, GPT-4 was evaluated on a variety of exams originally designed for humans.\n","====================\n","In\n","these evaluations it performs quite well and often outscores the vast majority of human test takers.\n","====================\n","For example, on a simulated bar exam, GPT-4 achieves a score that falls in the top 10% of test takers.\n","====================\n","This contrasts with GPT-3.5, which scores in the bottom 10%.\n","====================\n","On a suite of traditional NLP benchmarks, GPT-4 outperforms both previous large language models\n","and most state-of-the-art systems (which often have benchmark-speciﬁc training or hand-engineering).\n","====================\n","On the MMLU benchmark [ 35,36], an English-language suite of multiple-choice questions covering\n","57 subjects, GPT-4 not only outperforms existing models by a considerable margin in English, but\n","also demonstrates strong performance in other languages.\n","====================\n","On translated variants of MMLU, GPT-4\n","surpasses the English-language state-of-the-art in 24 of 26 languages considered.\n","====================\n","We discuss these\n","model capability results, as well as model safety improvements and results, in more detail in later\n","sections.\n","====================\n","This report also discusses a key challenge of the project, developing deep learning infrastructure and\n","optimization methods that behave predictably across a wide range of scales.\n","====================\n","This allowed us to make\n","predictions about the expected performance of GPT-4 (based on small runs trained in similar ways)\n","that were tested against the ﬁnal run to increase conﬁdence in our training.\n","====================\n","Despite its capabilities, GPT-4 has similar limitations to earlier GPT models [ 1,37,38]: it is not fully\n","reliable (e.g.\n","====================\n","can suffer from “hallucinations”), has a limited context window, and does not learn\n","\u0003Please cite this work as “OpenAI (2023)\".\n","====================\n","Full authorship contribution statements appear at the end of the\n","document.arXiv:2303.08774v2  [cs.CL]  16 Mar 2023\n","====================\n"]}]},{"cell_type":"code","source":["!pip install openai"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zf6wAcpJ6Oiy","executionInfo":{"status":"ok","timestamp":1679835562330,"user_tz":-480,"elapsed":12720,"user":{"displayName":"Liao Jack","userId":"16157886839679822522"}},"outputId":"f885bff4-b9e9-44b8-8159-19406b9b27ba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting openai\n","  Downloading openai-0.27.2-py3-none-any.whl (70 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 KB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.65.0)\n","Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.27.1)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (1.26.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.0.12)\n","Collecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (22.2.0)\n","Collecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n","Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.2 yarl-1.8.2\n"]}]},{"cell_type":"code","source":["import openai\n","\n","with open('api.txt', 'r') as f:\n","  openai.api_key = f.read()"],"metadata":{"id":"T76Lcmal-Os_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Note: you need to be using OpenAI Python v0.27.0 for the code below to work\n","import openai\n","\n","completion = openai.ChatCompletion.create(\n","  model=\"gpt-3.5-turbo\",\n","  messages=[\n","        {\"role\": \"system\", \"content\": \"請幫我翻譯, 翻譯成繁體中文\"},\n","        {\"role\": \"user\", \"content\": sentences[0]},\n","    ]\n",")"],"metadata":{"id":"2OuvHiCY6kq8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["completion.choices[0].message.content"],"metadata":{"id":"6oFxxBFF7JSq","executionInfo":{"status":"ok","timestamp":1679835566254,"user_tz":-480,"elapsed":10,"user":{"displayName":"Liao Jack","userId":"16157886839679822522"}},"colab":{"base_uri":"https://localhost:8080/","height":36},"outputId":"eccd072a-a7b6-423a-dec8-5a7e46b2f58b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'GPT-4 技術報告\\nOpenAI\\n摘要\\n本報告報導 GPT-4 的發展，這是一個大型、多模態模型，可以接受圖像和文字輸入並產生文字輸出。'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["input_sentences = ''\n","chunks = []\n","for sentence in sentences:\n","  input_sentences += sentence\n","  if len(input_sentences) > 1000:\n","    chunks.append(input_sentences)\n","    input_sentences = ''\n","chunks.append(input_sentences)"],"metadata":{"id":"IvqFBwIN7nY7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["chunks"],"metadata":{"id":"vr44ZeHl8DdE","executionInfo":{"status":"ok","timestamp":1679835566256,"user_tz":-480,"elapsed":9,"user":{"displayName":"Liao Jack","userId":"16157886839679822522"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"30a3b4ac-ad3f-4806-bd81-fc556052d6c8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['GPT-4 Technical Report\\nOpenAI\\x03\\nAbstract\\nWe report the development of GPT-4, a large-scale, multimodal model which can\\naccept image and text inputs and produce text outputs.While less capable than\\nhumans in many real-world scenarios, GPT-4 exhibits human-level performance\\non various professional and academic benchmarks, including passing a simulated\\nbar exam with a score around the top 10% of test takers.GPT-4 is a Transformer-\\nbased model pre-trained to predict the next token in a document.The post-training\\nalignment process results in improved performance on measures of factuality and\\nadherence to desired behavior.A core component of this project was developing\\ninfrastructure and optimization methods that behave predictably across a wide\\nrange of scales.This allowed us to accurately predict some aspects of GPT-4’s\\nperformance based on models trained with no more than 1/1,000th the compute of\\nGPT-4.1 Introduction\\nThis technical report presents GPT-4, a large multimodal model capable of processing image and\\ntext inputs and producing text outputs.',\n"," 'Such models are an important area of study as they have the\\npotential to be used in a wide range of applications, such as dialogue systems, text summarization,\\nand machine translation.As such, they have been the subject of substantial interest and progress in\\nrecent years [1–34].One of the main goals of developing such models is to improve their ability to understand and generate\\nnatural language text, particularly in more complex and nuanced scenarios.To test its capabilities\\nin such scenarios, GPT-4 was evaluated on a variety of exams originally designed for humans.In\\nthese evaluations it performs quite well and often outscores the vast majority of human test takers.For example, on a simulated bar exam, GPT-4 achieves a score that falls in the top 10% of test takers.This contrasts with GPT-3.5, which scores in the bottom 10%.On a suite of traditional NLP benchmarks, GPT-4 outperforms both previous large language models\\nand most state-of-the-art systems (which often have benchmark-speciﬁc training or hand-engineering).',\n"," 'On the MMLU benchmark [ 35,36], an English-language suite of multiple-choice questions covering\\n57 subjects, GPT-4 not only outperforms existing models by a considerable margin in English, but\\nalso demonstrates strong performance in other languages.On translated variants of MMLU, GPT-4\\nsurpasses the English-language state-of-the-art in 24 of 26 languages considered.We discuss these\\nmodel capability results, as well as model safety improvements and results, in more detail in later\\nsections.This report also discusses a key challenge of the project, developing deep learning infrastructure and\\noptimization methods that behave predictably across a wide range of scales.This allowed us to make\\npredictions about the expected performance of GPT-4 (based on small runs trained in similar ways)\\nthat were tested against the ﬁnal run to increase conﬁdence in our training.Despite its capabilities, GPT-4 has similar limitations to earlier GPT models [ 1,37,38]: it is not fully\\nreliable (e.g.can suffer from “hallucinations”), has a limited context window, and does not learn\\n\\x03Please cite this work as “OpenAI (2023)\".',\n"," 'Full authorship contribution statements appear at the end of the\\ndocument.arXiv:2303.08774v2  [cs.CL]  16 Mar 2023']"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["completion = openai.ChatCompletion.create(\n","  model=\"gpt-3.5-turbo\",\n","  messages=[\n","        {\"role\": \"system\", \"content\": \"請幫我翻譯, 翻譯成繁體中文\"},\n","        {\"role\": \"user\", \"content\": chunks[0]},\n","    ]\n",")\n","completion.choices[0].message.content"],"metadata":{"id":"HSI5jrln8JEl","executionInfo":{"status":"ok","timestamp":1679835582954,"user_tz":-480,"elapsed":16706,"user":{"displayName":"Liao Jack","userId":"16157886839679822522"}},"colab":{"base_uri":"https://localhost:8080/","height":88},"outputId":"344e0ffd-0a21-4b24-9042-a16cc3932b58"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'GPT-4 技術報告\\nOpenAI\\n\\n摘要\\n我們報告了 GPT-4 的開發，這是一個大規模的多模式模型，可以接受圖像和文本輸入並生成文本輸出。雖然在許多現實場景中不如人類能力強，但 GPT-4 在各種專業和學術基準測試中表現出人類水平的性能，包括通過模擬律師考試，得分在前 10%。GPT-4 是一個基於 Transformer 的模型，預訓練用於預測文檔中的下一個標記。後訓練對齊過程可以改善可靠性和符合預期行為的量測。該項目的核心組件是開發可以在各種規模上可預測地運作的基礎架構和優化方法。這使我們能夠根據使用不到 GPT-4 運算能力的模型進行準確的 GPT-4 性能預測。\\n\\n1 簡介\\n本技術報告介紹 GPT-4，一個大型多模式模型，能夠處理圖像和文本輸入並生成文本輸出。'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":["**全部過程**"],"metadata":{"id":"xRrtBalX8U3G"}},{"cell_type":"code","source":["from pypdf import PdfReader\n","from nltk.tokenize import sent_tokenize\n","\n","pdf_name = \"gpt-4.pdf\" #@param {type:\"string\"}\n","reader = PdfReader(pdf_name)\n","number_of_pages = len(reader.pages)\n","\n","chunks = []\n","\n","with open('gpt-4.txt', 'w') as f:\n","  for i in range(number_of_pages):\n","    page = reader.pages[i]\n","    text = page.extract_text()\n","    sentences = sent_tokenize(text)\n","    input_sentences = ''\n","    \n","    for sentence in sentences:\n","      input_sentences += sentence\n","      if len(input_sentences) > 1000:\n","        chunks.append(input_sentences)\n","        input_sentences = ''\n","    chunks.append(input_sentences)\n","\n","  for i in range(10):\n","    completion = openai.ChatCompletion.create(\n","    model=\"gpt-3.5-turbo\",\n","    messages=[\n","          {\"role\": \"system\", \"content\": \"請幫我翻譯, 翻譯成繁體中文\"},\n","          {\"role\": \"user\", \"content\": chunks[i]},\n","      ]\n","    )\n","    print('原文:', chunks[i])\n","    print('翻譯結果:', completion.choices[0].message.content)\n","    f.write(chunks[i])\n","    f.write(completion.choices[0].message.content)"],"metadata":{"id":"3OWTpmjy8YvY","executionInfo":{"status":"ok","timestamp":1679835781923,"user_tz":-480,"elapsed":152802,"user":{"displayName":"Liao Jack","userId":"16157886839679822522"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0f2bb29b-9711-4ffb-8ce3-579296c60b4f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["原文: GPT-4 Technical Report\n","OpenAI\u0003\n","Abstract\n","We report the development of GPT-4, a large-scale, multimodal model which can\n","accept image and text inputs and produce text outputs.While less capable than\n","humans in many real-world scenarios, GPT-4 exhibits human-level performance\n","on various professional and academic benchmarks, including passing a simulated\n","bar exam with a score around the top 10% of test takers.GPT-4 is a Transformer-\n","based model pre-trained to predict the next token in a document.The post-training\n","alignment process results in improved performance on measures of factuality and\n","adherence to desired behavior.A core component of this project was developing\n","infrastructure and optimization methods that behave predictably across a wide\n","range of scales.This allowed us to accurately predict some aspects of GPT-4’s\n","performance based on models trained with no more than 1/1,000th the compute of\n","GPT-4.1 Introduction\n","This technical report presents GPT-4, a large multimodal model capable of processing image and\n","text inputs and producing text outputs.\n","翻譯結果: GPT-4 技術報告\n","OpenAI\n","摘要\n","本報告介紹了 GPT-4 的開發，這是一個大型、多模式模型，可以接受圖像和文本輸入，並生成文本輸出。儘管在許多現實情況下比人類不如，但 GPT-4 在各種專業和學術基準測試中表現出人類水平的性能，包括通過模擬的律師考試，得分為前 10% 的考生。GPT-4 是基於 Transformer 的模型，預先訓練來預測文檔中的下一個令牌。後訓練對齊過程提高了它在事實準確度和符合期望行為方面的性能。本項目的核心組件是開發基礎架構和優化方法，以在各種規模下具有可預測的行為。這使我們能夠根據使用不到 GPT-4 計算能力的模型正確預測 GPT-4 的某些方面性能。\n","1 引言\n","本技術報告介紹了 GPT-4，這是一個大型多模式模型，能夠處理圖像和文本輸入，生成文本輸出。\n","原文: Such models are an important area of study as they have the\n","potential to be used in a wide range of applications, such as dialogue systems, text summarization,\n","and machine translation.As such, they have been the subject of substantial interest and progress in\n","recent years [1–34].One of the main goals of developing such models is to improve their ability to understand and generate\n","natural language text, particularly in more complex and nuanced scenarios.To test its capabilities\n","in such scenarios, GPT-4 was evaluated on a variety of exams originally designed for humans.In\n","these evaluations it performs quite well and often outscores the vast majority of human test takers.For example, on a simulated bar exam, GPT-4 achieves a score that falls in the top 10% of test takers.This contrasts with GPT-3.5, which scores in the bottom 10%.On a suite of traditional NLP benchmarks, GPT-4 outperforms both previous large language models\n","and most state-of-the-art systems (which often have benchmark-speciﬁc training or hand-engineering).\n","翻譯結果: 這些模型是重要的研究領域，因為它們具有應用廣泛的潛力，例如對話系統、文本摘要和機器翻譯。因此，在近年來，這些模型一直受到廣泛的關注和進展[1-34]。開發這些模型的主要目標之一是提高它們理解和生成自然語言文本的能力，特別是在更複雜和微妙的情況下。為了測試其在這些情況下的能力，GPT-4被評估在一系列原本設計給人類的考試中。在這些評估中，它表現出色，常常超越大多數考試參加者的成績。例如，在一個模擬的酒吧考試中，GPT-4獲得的分數位於前10％的考試參加者中。這與GPT-3.5形成對比，後者的分數位於最低的10％。在一系列傳統的自然語言處理基準測試中，GPT-4不僅超越以前的大型語言模型，也優於大多數最先進的系統（這些系統經常具有基準特定的訓練或手動工程）。\n","原文: On the MMLU benchmark [ 35,36], an English-language suite of multiple-choice questions covering\n","57 subjects, GPT-4 not only outperforms existing models by a considerable margin in English, but\n","also demonstrates strong performance in other languages.On translated variants of MMLU, GPT-4\n","surpasses the English-language state-of-the-art in 24 of 26 languages considered.We discuss these\n","model capability results, as well as model safety improvements and results, in more detail in later\n","sections.This report also discusses a key challenge of the project, developing deep learning infrastructure and\n","optimization methods that behave predictably across a wide range of scales.This allowed us to make\n","predictions about the expected performance of GPT-4 (based on small runs trained in similar ways)\n","that were tested against the ﬁnal run to increase conﬁdence in our training.Despite its capabilities, GPT-4 has similar limitations to earlier GPT models [ 1,37,38]: it is not fully\n","reliable (e.g.can suffer from “hallucinations”), has a limited context window, and does not learn\n","\u0003Please cite this work as “OpenAI (2023)\".\n","翻譯結果: 在MMLU基準測試中[35,36]，這是一個英語的多項選擇問題套件，涵蓋57個科目，GPT-4不僅在英語方面大幅優於現有模型，而且在其他語言上的表現也非常強勁。在MMLU的翻譯變體中，GPT-4在26種語言中的24種語言中均超越了英語的最新水平。我們將在後面的章節中更詳細地討論這些模型能力結果，以及模型安全性的改進和結果。本報告還討論了該項目的一個關鍵挑戰，即開發能夠在各種規模上可預測地運作的深度學習基礎架構和優化方法。這使我們能夠對GPT-4的預期表現（基於類似方式訓練的小型運行）進行預測，並將其與最終運行進行測試以增強我們的訓練信心。儘管GPT-4具有類似於之前GPT模型[1,37,38]的功能，但它並不完全可靠（例如可能會出現“幻覺”），上下文窗口有限，並且無法學習。請引用此工作為“OpenAI（2023年)”。\n","原文: Full authorship contribution statements appear at the end of the\n","document.arXiv:2303.08774v2  [cs.CL]  16 Mar 2023\n","翻譯結果: 完整的作者貢獻聲明將在本文件的末尾出現.arXiv:2303.08774v2  [cs.CL]  16 Mar 2023\n","原文: from experience.Care should be taken when using the outputs of GPT-4, particularly in contexts\n","where reliability is important.GPT-4’s capabilities and limitations create signiﬁcant and novel safety challenges, and we believe\n","careful study of these challenges is an important area of research given the potential societal impact.This report includes an extensive system card (after the Appendix) describing some of the risks we\n","foresee around bias, disinformation, over-reliance, privacy, cybersecurity, proliferation, and more.It also describes interventions we made to mitigate potential harms from the deployment of GPT-4,\n","including adversarial testing with domain experts, and a model-assisted safety pipeline.2 Scope and Limitations of this Technical Report\n","This report focuses on the capabilities, limitations, and safety properties of GPT-4.GPT-4 is a\n","Transformer-style model [ 39] pre-trained to predict the next token in a document, using both publicly\n","available data (such as internet data) and data licensed from third-party providers.\n","翻譯結果: 從經驗來看，使用GPT-4的輸出時應該要小心，特別是在可靠性重要的情況下。GPT-4的能力和限制創造了重大和新穎的安全挑戰，我們認為仔細研究這些挑戰是研究重要領域，因為潛在的社會影響非常大。本報告包括一個廣泛的系統卡（附錄後）描述我們預見到的一些風險，例如偏見、錯誤信息、過度依賴、隱私、網絡安全、擴散等等。報告中還描述了我們采取的干預措施，以減輕GPT-4部署可能造成的潛在危害，包括與領域專家進行對抗測試和模型輔助安全通道。此技術報告的範圍和限制集中在GPT-4的能力、限制和安全性質上。GPT-4是一種Transformer風格的模型[39]，預先訓練以預測文檔中的下一個令牌，使用公開可用的數據（如互聯網數據）和從第三方供應商許可的數據。\n","原文: The model was\n","then ﬁne-tuned using Reinforcement Learning from Human Feedback (RLHF) [ 40].Given both\n","the competitive landscape and the safety implications of large-scale models like GPT-4, this report\n","contains no further details about the architecture (including model size), hardware, training compute,\n","dataset construction, training method, or similar.We are committed to independent auditing of our technologies, and shared some initial steps and\n","ideas in this area in the system card accompanying this release.2We plan to make further technical\n","details available to additional third parties who can advise us on how to weigh the competitive and\n","safety considerations above against the scientiﬁc value of further transparency.3 Predictable Scaling\n","A large focus of the GPT-4 project was building a deep learning stack that scales predictably.The\n","primary reason is that for very large training runs like GPT-4, it is not feasible to do extensive\n","model-speciﬁc tuning.To address this, we developed infrastructure and optimization methods that\n","have very predictable behavior across multiple scales.\n","翻譯結果: 該模型隨後使用人工回饋強化學習（RLHF）[40]進行了微調。考慮到像GPT-4這樣的大型模型的競爭環境和安全影響，本報告未涉及架構（包括模型大小）、硬件、訓練計算、數據集構建、訓練方法或類似技術的進一步詳細信息。我們致力於獨立審計我們的技術，並在附帶此版本的系統卡中分享了一些初步的步驟和想法。我們計劃向其他第三方提供進一步的技術細節，以便他們向我們建議如何權衡上述競爭和安全考慮與進一步透明度的科學價值。可預測的擴張是GPT-4項目的一個重要焦點，我們致力於構建一個能夠可預測地擴大的深度學習堆棧。主要原因是對於像GPT-4這樣的大型訓練運行，不可行進行廣泛的模型特定調整。為了解決這個問題，我們開發了基礎架構和優化方法，這些方法在多個尺度上有非常可預測的行為。\n","原文: These improvements allowed us to reliably\n","predict some aspects of the performance of GPT-4 from smaller models trained using 1;000\u0002–\n","10;000\u0002less compute.3.1 Loss Prediction\n","The ﬁnal loss of properly-trained large language models is thought to be well approximated by power\n","laws in the amount of compute used to train the model [41, 42, 2, 14, 15].To verify the scalability of our optimization infrastructure, we predicted GPT-4’s ﬁnal loss on our\n","internal codebase (not part of the training set) by ﬁtting a scaling law with an irreducible loss term\n","(as in Henighan et al.[15]):L(C) =aCb+c;from models trained using the same methodology\n","but using at most 10,000x less compute than GPT-4.This prediction was made shortly after the run\n","started, without use of any partial results.The ﬁtted scaling law predicted GPT-4’s ﬁnal loss with\n","high accuracy (Figure 1).3.2 Scaling of Capabilities on HumanEval\n","Having a sense of the capabilities of a model before training can improve decisions around alignment,\n","safety, and deployment.\n","翻譯結果: 這些改進使我們能夠可靠地從使用更少的計算資源(1,000至10,000倍)進行訓練的較小模型中預測GPT-4的某些性能方面。3.1 損失預測通過擬合帶有不可簡化損失項的比例定律(如Henighan等人所述)，我們預測了在內部代碼庫上(不是訓練集的一部分)的GPT-4的最終損失，使用的是相同的方法進行訓練，但是使用的計算資源最多不到GPT-4的十分之一。這個預測是在運行開始後不久進行的，沒有使用任何部分結果。擬合的比例定律以高精度預測了GPT-4的最終損失(見圖1)。3.2 能力在人類評估上的縮放在進行訓練之前了解模型的能力可以改進關於對齊、安全和部署的決策。\n","原文: In addition to predicting ﬁnal loss, we developed methodology to predict\n","more interpretable metrics of capability.One such metric is pass rate on the HumanEval dataset [ 43],\n","which measures the ability to synthesize Python functions of varying complexity.We successfully\n","predicted the pass rate on a subset of the HumanEval dataset by extrapolating from models trained\n","with at most 1;000\u0002less compute (Figure 2).For an individual problem in HumanEval, performance may occasionally worsen with scale.Despite\n","these challenges, we ﬁnd an approximate power law relationship \u0000EP[log(pass _rate(C))] = \u000b\u0003C\u0000k\n","2In addition to the accompanying system card, OpenAI will soon publish additional thoughts on the social\n","and economic implications of AI systems, including the need for effective regulation.2\n","翻譯結果: 除了預測最終損失之外，我們開發了一種方法來預測更易於解釋的能力指標。其中一種指標是對人類評估數據集 [43] 的通過率，該數據集衡量了綜合 Python 函數的能力，這些函數具有不同的複雜度。我們成功預測了在小型的 HumanEval 子集上的通過率，通過對最多使用 1,000 倍計算的模型進行推斷 (圖2)。對於 HumanEval 中的個別問題，隨著規模擴大，性能偶爾可能會惡化。儘管存在這些挑戰，我們發現了一個近似的冪律關係 EP [log(pass_rate(C))] = C^k。除了相應的系統卡，OpenAI 很快將發表有關 AI 系統社會和經濟影響的其他想法，包括有效監管的需求。\n","原文: Observed\n","Prediction\n","gpt-4\n","100p 10n 1µ 100µ 0.01 1\n","Compute1.02.03.04.05.06.0Bits per wordOpenAI codebase next word predictionFigure 1.Performance of GPT-4 and smaller models.The metric is ﬁnal loss on a dataset derived\n","from our internal codebase.This is a convenient, large dataset of code tokens which is not contained in\n","the training set.We chose to look at loss because it tends to be less noisy than other measures across\n","different amounts of training compute.A power law ﬁt to the smaller models (excluding GPT-4) is\n","shown as the dotted line; this ﬁt accurately predicts GPT-4’s ﬁnal loss.The x-axis is training compute\n","normalized so that GPT-4 is 1.Observed\n","Prediction\n","gpt-4\n","1µ 10µ 100µ 0.001 0.01 0.1 1\n","Compute012345– Mean Log Pass RateCapability prediction on 23 coding problems\n","Figure 2.Performance of GPT-4 and smaller models.The metric is mean log pass rate on a subset of\n","the HumanEval dataset.A power law ﬁt to the smaller models (excluding GPT-4) is shown as the dotted\n","line; this ﬁt accurately predicts GPT-4’s performance.\n","翻譯結果: 觀察到的\n","預測\n","gpt-4\n","100p 10n 1µ 100µ 0.01 1\n","計算1.02.03.04.05.06.0每字節位元數OpenAI程式庫下一個字的預測圖1.GPT-4及較小模型的性能。評估指標是從我們內部程式庫派生的數據集的最終損失。這是一個方便的、大規模的代碼令牌數據集，不包含在訓練集中。我們選擇觀察損失是因為它在不同程度的訓練計算下通常比其他測量更穩定。較小模型（不包括GPT-4）的冪律擬合線用虛線表示；這個擬合能夠準確預測GPT-4的最終損失。x軸是訓練計算歸一化，以使GPT-4的值為1。觀察到的\n","預測\n","gpt-4\n","1µ 10µ 100µ 0.001 0.01 0.1 1\n","計算012345– 平均對數通過率能力預測的23個編程問題\n","圖2.GPT-4及較小模型的性能。評估指標是在HumanEval數據集的子集上的平均對數通過率。較小模型（不包括GPT-4）的冪律擬合線用虛線表示；這個擬合能夠準確預測GPT-4的性能。\n","原文: The x-axis is training compute normalized so that\n","GPT-4 is 1.3\n","翻譯結果: x軸是以訓練計算被標準化，使得GPT-4的值為1.3。\n"]}]}]}